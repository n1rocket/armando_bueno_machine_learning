{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Casos prácticos\n",
    "\n",
    "En este notebook vamos a abordar dos casos prácticos interesantes.\n",
    "\n",
    "1. Predicción (*forecasting*) de la demanda de bicicletas\n",
    "2. Clasificación multiclase de imágenes\n",
    "\n",
    "## Librerías y funciones\n",
    "\n",
    "Lo primero es cargar las librerías y funciones necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confmat):\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.5)\n",
    "    for i in range(confmat.shape[0]):\n",
    "        for j in range(confmat.shape[1]):\n",
    "            ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "\n",
    "    plt.xlabel('predicted label')\n",
    "    plt.ylabel('true label')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Predicción de la demanda de bicicletas\n",
    "\n",
    "El problema está descrito [aquí](https://christophm.github.io/interpretable-ml-book/bike-data.html), y los datos pueden descargarse en la [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset), aunque los hemos modificado un poco para hacer el problema más parecido al [*challenge*](https://www.kaggle.com/c/bike-sharing-demand/data) original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/bikes.csv',sep=';', decimal='.')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Interprete los datos y realiza tus primeras hipótesis sobre qué variables son de interés\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Elimine las columnas *instant*, *casual* y *registered*\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTA IMPORTANTE: \n",
    "\n",
    "Todos los datasets que hemos usado están preprocesados mínimamente: no hay valores ausentes, pocos outliers... en la realidad y en la práctica final no va a ser así. El tratamiento de outliers es un poco artesanal: se puede hacer con un filtro, por ejemplo, como ya hemos visto, o analizando manualmente los scatter plots. \n",
    "\n",
    "Para los valores ausentes, hay que imputar. Es muy sencillo con pandas, usando ``fillna``:\n",
    "\n",
    "``df[\"Feature\"].fillna(df[\"Feature\"].mode()[0], inplace=True)``\n",
    "\n",
    "El caso de arriba rellena con la moda (valor más frecuente), en otras ocasiones es preferible usar la media, y en algunos (pocos) casos se puede hacer con ceros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 *Feature Engineering*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trabajar con las fechas para crear algunas variables auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "data['dteday'] = data['dteday'].apply(lambda x: datetime.strptime(x,'%d-%m-%Y'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['year'] = data['dteday'].apply(lambda x: x.year - 2011)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['month'] = data['dteday'].apply(lambda x: x.month)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['weekday'] = data['dteday'].apply(lambda x: x.isoweekday())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llegados a este punto, podemos eliminar la variable *dteday*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['dteday'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Análisis de correlación\n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Represente la variable *temp* vs *atemp*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la vista está que son variables altamente correlacionadas. Podemos eliminar *temp*, ya que nos afecta más la sensación térmica que la temperatura real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['temp'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**(@home): Realice un análisis exploratorio exhaustivo.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Codificación de variables categóricas\n",
    "\n",
    "Tenemos varias variables categóricas: *season*, *weathersit*, *month* y *weekday*. Cuando trabajamos con series temporales, es común crear variables *dummies* asociadas a cada una de las situaciones de las variables categóricas. Para ello, tenemos dos opciones:\n",
    "\n",
    "- [pd.get_dummies()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html): se aplica directamente sobre el dataframe puede [utilizarse](https://towardsdatascience.com/the-dummys-guide-to-creating-dummy-variables-f21faddb1d40) con strings directamente. La pega es que genera un nuevo dataframe que hay que agregar al original.\n",
    "- [MeanEncoder](https://maxhalford.github.io/blog/target-encoding/): no está implementado (que yo sepa) en scikit learn pero mola tanto que da igual. Asigna un valor a cada variable categórica según la media de la columna objetivo para el conjunto de registros que tienen esa variable categórica. Es decir, si quisiera categorizar la variable \"Barrio\" con un ME, lo que tendría que hacer es calcular la media de precio en cada barrio (Villaverde, Chamberí, etc) y sustituir el nombre del barrio por esa media. Ojito con el data leakage, os dejo un ejemplo debajo de cómo hacerlo bien.\n",
    "\n",
    "Tutoriales sobre codificación de variables categóricas: [Tutorial 1](https://towardsdatascience.com/encoding-categorical-features-21a2651a065c), [tutorial 2](https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02)\n",
    "\n",
    "La codificación \"dummy\" de variables categóricas en problemas de clasificación/regresión es opcional, como vimos anteriormente, pero en series temporales resulta adecuado para explicar el efecto de una situación temporal en la variable target.\n",
    "\n",
    "Vamos a utilizar los dos métodos para codificar las variables categóricas.  \n",
    "\n",
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**(@home): Prueba no realizar esta codificación \"dummy\" y entrena un modelo de machine learning para predecir la demanda de bicicletas.\n",
    "</div>\n",
    "\n",
    "Comenzamos por la variable *season*. Veamos qué hace *get_dummies()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data['season'], prefix = 'season')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = pd.get_dummies(data['season'], prefix = 'season')\n",
    "\n",
    "data = pd.concat([data,dummy],axis=1).drop(['season'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['weathersit', 'month', 'weekday']\n",
    "\n",
    "mean_map = {}\n",
    "for c in categorical:\n",
    "    mean = data.groupby(c)['cnt'].mean()\n",
    "    data[c] = data[c].map(mean)    \n",
    "    mean_map[c] = mean\n",
    "\n",
    "# Si hubiera test, luego se haría:\n",
    "#for c in categorical:\n",
    "#    data_test[c] = data_test[c].map(mean_map[c])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es uno de los tutoriales más completos que he visto: [Encoding done the right way](https://maxhalford.github.io/blog/target-encoding-done-the-right-way/) y me hace especial gracia porque dice esto: \"Label encoding is useless and you should never use it\". No estoy 100% de acuerdo obviamente :) pero sí que es cierto que cuando hay muchas categorías (es decir, no es binario) un LE puede llevar a errores porque asigna números a cada una de ellas, con lo cual el algoritmo puede \"aprender\" erróneamente. Supongamos que tengo una categoría barrio que quiero categorizar:\n",
    "\n",
    "- Barrio céntrico moderno y caro -> LE -> 1\n",
    "- Otro barrio -> LE -> 2\n",
    "- Otro más -> LE -> 3\n",
    "- Y otro -> LE -> 4\n",
    "- Barrio periférico y obrero -> LE -> 5\n",
    "\n",
    "Mis categorías tras el LE pasarían a ser 1-5, pero qué quiere decir esto? Que 5 es mayor que 1? Que 3 es menor que 5? No, porque no existe esa relación entre los barrios, pero SÍ entre los números! Entonces el algoritmo podría decidir que de alguna manera \"Barrio periférico y obrero > Barrio céntrico moderno y caro\" porque 5 > 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 División train/test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparamos los datos\n",
    "features = data.columns.drop(['cnt'])\n",
    "X = data[features].values\n",
    "y = data['cnt'].values\n",
    "\n",
    "print('Filas, columnas', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1:\n",
    "offset = 182 # 0.25 of 731\n",
    "\n",
    "X_train = X[:-offset, :]\n",
    "y_train = y[:-offset]\n",
    "X_test  = X[-offset:, :]\n",
    "y_test  = y[-offset:]\n",
    "\n",
    "plt.plot(range(0,len(y_train)),y_train, label='train')\n",
    "plt.plot(range(len(y_train),len(y)),y_test,label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Búsqueda de parámetros libres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "alpha_vector = np.logspace(-4,4,20)\n",
    "param_grid = {'alpha': alpha_vector}\n",
    "\n",
    "grid = GridSearchCV(Lasso(), param_grid=param_grid, cv = tscv.split(X_train)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best mean cross-validation score: {:.3f}\".format(grid.best_score_))\n",
    "print(\"best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "scores = grid.cv_results_['mean_test_score']\n",
    "std_scores = grid.cv_results_['std_test_score']\n",
    "plt.errorbar(np.log10(alpha_vector),scores,yerr=std_scores, fmt='o-',ecolor='g')\n",
    "plt.xlabel('log(alpha)',fontsize=16)\n",
    "plt.ylabel('CV MSE')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Métricas en test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "alpha_optimo = grid.best_params_['alpha']\n",
    "lasso = Lasso(alpha = alpha_optimo).fit(X_train,y_train)\n",
    "\n",
    "ytrainLasso = lasso.predict(X_train)\n",
    "ytestLasso  = lasso.predict(X_test)\n",
    "\n",
    "mseTrainModelLasso = mean_squared_error(y_train,ytrainLasso)\n",
    "mseTestModelLasso = mean_squared_error(y_test,ytestLasso)\n",
    "\n",
    "print('MSE Modelo Lasso (train): %0.3g' % mseTrainModelLasso)\n",
    "print('MSE Modelo Lasso (test) : %0.3g' % mseTestModelLasso)\n",
    "\n",
    "w = lasso.coef_\n",
    "for f,wi in zip(features,w):\n",
    "    print(f,wi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Representa la predicción obtenida junto con la serie real (train+test)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clasificación multiclase de imágenes\n",
    "\n",
    "En este caso vamos a utilizar la famosa base de datos de [MNIST](http://yann.lecun.com/exdb/mnist/). Esta base de datos contiene\n",
    "\n",
    "* Training set: train-images-idx3-ubyte.gz (9.9 MB, 47 MB unzipped, 60,000 samples)\n",
    "* Training set labels: train-labels-idx1-ubyte.gz (29 KB, 60 KB unzipped, 60,000 labels)\n",
    "* Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 7.8 MB, 10,000 samples)\n",
    "* Test set labels: t10k-labels-idx1-ubyte.gz (5 KB, 10 KB unzipped, 10,000 labels)\n",
    "\n",
    "Estas imágenes se pueden descargar a partir del siguiente código (previamente hay que descargarse los archivos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import gzip\n",
    " \n",
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path, \n",
    "                               '%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, \n",
    "                               '%s-images-idx3-ubyte.gz' % kind)\n",
    "        \n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        lbpath.read(8)\n",
    "        buffer = lbpath.read()\n",
    "        labels = np.frombuffer(buffer, dtype=np.uint8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        imgpath.read(16)\n",
    "        buffer = imgpath.read()\n",
    "        images = np.frombuffer(buffer, \n",
    "                               dtype=np.uint8).reshape(\n",
    "            len(labels), 784).astype(np.float64)\n",
    " \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto os va a fallar si no lo tenéis bajado; da igual\n",
    "\n",
    "#X_train, y_train = load_mnist('./data/mnist/', kind='train')\n",
    "#print('Rows: %d, columns: %d' % (X_train.shape[0], X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test, y_test = load_mnist('mnist/', kind='t10k')\n",
    "#print('Rows: %d, columns: %d' % (X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obstante, sklearn tiene la base de datos incluida en sus datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "# rescale the data, use the traditional train/test split\n",
    "X, y = mnist.data / 255., mnist.target\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Fíjate que el conjunto de entrenamiento son los pixels de la imagen tal cual!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"X train shape: \", X_train.shape)\n",
    "print (\"y train shape: \", y_train.shape)\n",
    "print (\"X test shape: \",  X_test.shape)\n",
    "print (\"y test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Entrena un modelo de regresión logística con C = 10 y calcula sus prestaciones en el conjunto de test. A lo mejor te resulta de utilidad revisar la [documentación](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\">\n",
    "**EJERCICIO**: Calcula y representa la matriz de confusión, ¿qué conclusiones puedes sacar?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pequeña ayuda para la práctica final\n",
    "\n",
    "El método ``train_test_split`` es mucho más potente que lo que hemos visto en clase, y permite hacer muchas más cosas. En clase siempre hemos particionado en cuatro (xtrain, xtest, ytrain, ytest) obteniendo arrays de numpy, pero no es la única opción. Aquí tenéis un único fichero .csv, y podéis usar la función para obtener dos subconjuntos: train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_df = pd.read_csv('./airbnb-listings-extract.csv', sep=';', decimal='.')\n",
    "train, test = train_test_split(full_df, test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "print(f'Dimensiones del dataset de training: {train.shape}')\n",
    "print(f'Dimensiones del dataset de test: {test.shape}')\n",
    "\n",
    "# Guardamos\n",
    "train.to_csv('./train.csv', sep=';', decimal='.', index=False)\n",
    "test.to_csv('./test.csv', sep=';', decimal='.', index=False)\n",
    "\n",
    "# A partir de este momento cargamos el dataset de train y trabajamos ÚNICAMENTE con él. \n",
    "\n",
    "df = pd.read_csv('./train.csv', sep=';', decimal='.')\n",
    "\n",
    "# etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de dividir en ``X`` e ``y`` lo que tendréis que hacer es algo como esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "data = df.values\n",
    "y_train = data[:,0:1]     # nos quedamos con la 1ª columna, price\n",
    "X_train = data[:,1:]      # nos quedamos con el resto\n",
    "feature_names = df.columns[1:]\n",
    "# Escalamos (con los datos de train)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "XtrainScaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y cuando queráis ya evaluar el modelo (después de hacer CV y demás) tendréis que cargar el csv de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./test.csv', sep=';', decimal='.')\n",
    "\n",
    "# aplicarle LAS MISMAS transformaciones que hayáis hecho en train \n",
    "#(drop de columnas, filtros, generaciones, fill...) y sacar los datos:\n",
    "\n",
    "data_test = df_test.values\n",
    "y_test = data_test[:,0:1]     # nos quedamos con la 1ª columna, price\n",
    "X_test = data_test[:,1:]      # nos quedamos con el resto\n",
    "feature_names_test = df_test.columns[1:]\n",
    "\n",
    "# recordad que esta normalización/escalado la realizo con el scaler anterior, basado en los datos de training!\n",
    "XtestScaled = scaler.transform(X_test) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
